{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "970e3be1",
   "metadata": {},
   "source": [
    "Цей код створює 2 окремі датафрейми:\n",
    "- df_duration_ouliers - містить аутлаєри по часу поїздки > 24 годин.\n",
    "- df - містить сирі дані очищені від аутлаєрів > 24 годин.\n",
    "\n",
    "В обох датафреймах міститься ще 2 додаткові колонки: started_at_dt і ended_at_dt, що містять час початку і кінця поїздки в типі datetime в таймзомі міста Осло."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "670b43b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime\n",
    "import time\n",
    "import helpful_functions\n",
    "import pytz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "cc3750e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "city_name = 'trondheim'        # можливі варіанти: olso, bergen, trondheim\n",
    "\n",
    "start_month = 5           # 1 - 12\n",
    "start_year = 2018         # 2019 - 2022\n",
    "\n",
    "end_month = 6             # 1 - 12\n",
    "end_year = 2022           # 2019 - 2022\n",
    "\n",
    "data_folder = './data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f9d9316b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dates_str_list = helpful_functions.generate_months_in_period(\n",
    "    start_month=start_month, \n",
    "    start_year=start_year, \n",
    "    end_month=end_month, \n",
    "    end_year=end_year, \n",
    "    sep=\"_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ab949bad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Зчитування:  6.321700096130371 с. \n",
      "\n",
      "Розмір початкової таблиці:  (781422, 13)\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "df = pd.read_csv(f\"{data_folder}/{city_name}/{city_name}_{dates_str_list[0]}.csv\")\n",
    "for date in dates_str_list[1:]:\n",
    "    try:\n",
    "        df = pd.concat([df, pd.read_csv(f\"{data_folder}/{city_name}/{city_name}_{date}.csv\")])\n",
    "    except:\n",
    "        pass\n",
    "end = time.time()\n",
    "print(\"Зчитування: \", end - start, \"с. \\n\")\n",
    "print(\"Розмір початкової таблиці: \", df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "63733820",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Трансформування:  34.44571495056152 с.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>started_at</th>\n",
       "      <th>ended_at</th>\n",
       "      <th>duration</th>\n",
       "      <th>start_station_id</th>\n",
       "      <th>start_station_name</th>\n",
       "      <th>start_station_description</th>\n",
       "      <th>start_station_latitude</th>\n",
       "      <th>start_station_longitude</th>\n",
       "      <th>end_station_id</th>\n",
       "      <th>end_station_name</th>\n",
       "      <th>end_station_description</th>\n",
       "      <th>end_station_latitude</th>\n",
       "      <th>end_station_longitude</th>\n",
       "      <th>started_at_dt</th>\n",
       "      <th>ended_at_dt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-05-15 09:07:43.961000+00:00</td>\n",
       "      <td>2018-05-15 09:10:33.267000+00:00</td>\n",
       "      <td>169</td>\n",
       "      <td>28</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>63.430457</td>\n",
       "      <td>10.398101</td>\n",
       "      <td>35</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>63.432504</td>\n",
       "      <td>10.400387</td>\n",
       "      <td>2018-05-15 11:07:43+02:00</td>\n",
       "      <td>2018-05-15 11:10:33+02:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-05-15 09:07:51.044000+00:00</td>\n",
       "      <td>2018-05-15 09:10:34.085000+00:00</td>\n",
       "      <td>163</td>\n",
       "      <td>28</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>63.430457</td>\n",
       "      <td>10.398101</td>\n",
       "      <td>35</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>63.432504</td>\n",
       "      <td>10.400387</td>\n",
       "      <td>2018-05-15 11:07:51+02:00</td>\n",
       "      <td>2018-05-15 11:10:34+02:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-05-15 09:10:50.177000+00:00</td>\n",
       "      <td>2018-05-15 09:15:33.270000+00:00</td>\n",
       "      <td>283</td>\n",
       "      <td>35</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>63.432504</td>\n",
       "      <td>10.400387</td>\n",
       "      <td>66</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>63.435277</td>\n",
       "      <td>10.405814</td>\n",
       "      <td>2018-05-15 11:10:50+02:00</td>\n",
       "      <td>2018-05-15 11:15:33+02:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-05-15 09:11:28.089000+00:00</td>\n",
       "      <td>2018-05-15 09:15:34.746000+00:00</td>\n",
       "      <td>246</td>\n",
       "      <td>35</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>63.432504</td>\n",
       "      <td>10.400387</td>\n",
       "      <td>66</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>63.435277</td>\n",
       "      <td>10.405814</td>\n",
       "      <td>2018-05-15 11:11:28+02:00</td>\n",
       "      <td>2018-05-15 11:15:34+02:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-05-15 09:14:21.231000+00:00</td>\n",
       "      <td>2018-05-15 09:15:32.835000+00:00</td>\n",
       "      <td>71</td>\n",
       "      <td>35</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>63.432504</td>\n",
       "      <td>10.400387</td>\n",
       "      <td>35</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>63.432504</td>\n",
       "      <td>10.400387</td>\n",
       "      <td>2018-05-15 11:14:21+02:00</td>\n",
       "      <td>2018-05-15 11:15:32+02:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         started_at                          ended_at  \\\n",
       "0  2018-05-15 09:07:43.961000+00:00  2018-05-15 09:10:33.267000+00:00   \n",
       "1  2018-05-15 09:07:51.044000+00:00  2018-05-15 09:10:34.085000+00:00   \n",
       "2  2018-05-15 09:10:50.177000+00:00  2018-05-15 09:15:33.270000+00:00   \n",
       "3  2018-05-15 09:11:28.089000+00:00  2018-05-15 09:15:34.746000+00:00   \n",
       "4  2018-05-15 09:14:21.231000+00:00  2018-05-15 09:15:32.835000+00:00   \n",
       "\n",
       "  duration start_station_id start_station_name start_station_description  \\\n",
       "0      169               28                NaN                             \n",
       "1      163               28                NaN                             \n",
       "2      283               35                NaN                             \n",
       "3      246               35                NaN                             \n",
       "4       71               35                NaN                             \n",
       "\n",
       "  start_station_latitude start_station_longitude end_station_id  \\\n",
       "0              63.430457               10.398101             35   \n",
       "1              63.430457               10.398101             35   \n",
       "2              63.432504               10.400387             66   \n",
       "3              63.432504               10.400387             66   \n",
       "4              63.432504               10.400387             35   \n",
       "\n",
       "  end_station_name end_station_description end_station_latitude  \\\n",
       "0              NaN                                    63.432504   \n",
       "1              NaN                                    63.432504   \n",
       "2              NaN                                    63.435277   \n",
       "3              NaN                                    63.435277   \n",
       "4              NaN                                    63.432504   \n",
       "\n",
       "  end_station_longitude             started_at_dt               ended_at_dt  \n",
       "0             10.400387 2018-05-15 11:07:43+02:00 2018-05-15 11:10:33+02:00  \n",
       "1             10.400387 2018-05-15 11:07:51+02:00 2018-05-15 11:10:34+02:00  \n",
       "2             10.405814 2018-05-15 11:10:50+02:00 2018-05-15 11:15:33+02:00  \n",
       "3             10.405814 2018-05-15 11:11:28+02:00 2018-05-15 11:15:34+02:00  \n",
       "4             10.400387 2018-05-15 11:14:21+02:00 2018-05-15 11:15:32+02:00  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "strptime_pattern = \"%Y-%m-%d %H:%M:%S%z\"\n",
    "timezone = pytz.timezone('Europe/Oslo')\n",
    "\n",
    "start = time.time()\n",
    "df['started_at_dt'] = df['started_at'].apply(lambda x: datetime.datetime.strptime(x[:-6].split('.')[0] + x[-6:], strptime_pattern).astimezone(timezone))\n",
    "df['ended_at_dt'] = df['ended_at'].apply(lambda x: datetime.datetime.strptime(x[:-6].split('.')[0] + x[-6:], strptime_pattern).astimezone(timezone))\n",
    "end = time.time()\n",
    "print(\"Трансформування: \", end - start, \"с.\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "04db5326",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_start_stations = df[['start_station_id',\n",
    "                        'start_station_name',\n",
    "                           'start_station_description', \n",
    "                           'start_station_latitude', \n",
    "                           'start_station_longitude']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c1d722d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_start_stations = df_start_stations.drop_duplicates(subset=['start_station_id'],\n",
    "                                                     keep='last')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7ae3e988",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(75, 5)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_start_stations.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "070f5412",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_start_stations = df_start_stations.rename(columns={'start_station_id': 'station_id',\n",
    "                                                     'start_station_name': 'station_name',\n",
    "                                                     'start_station_description': 'station_description',\n",
    "                                                     'start_station_latitude': 'station_latitude',\n",
    "                                                     'start_station_longitude': 'station_longitude'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4a89d0c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_start_stations.to_csv(f'./data/{city_name}_stations.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "2a4c30f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[['started_at_dt', 'ended_at_dt', 'duration', 'start_station_id', 'end_station_id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b3e94123",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(781422, 5)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3904f013",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9587be11",
   "metadata": {},
   "source": [
    "Створюємо 2 датафрейми: \n",
    "- df_duration_ouliers - містить аутлаєри по часу поїздки > 24 годин. Потрібний для подальшого аналізу цих аутлаєрів.\n",
    "- df - містить сирі дані очищені від аутлаєрів > 24 годин. Для подальшого аналізу."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "9f9a65a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_duration_outliers = df[df['duration'] > 24 * 60 * 60]\n",
    "df = df[df['duration'] <= 24 * 60 * 60]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "f152087f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17.072633028030396"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start = time.time()\n",
    "df.to_csv(f'./data/{city_name}_clear_rides_data.csv', index=False)\n",
    "end = time.time()\n",
    "end - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "91dd3dc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.007395029067993164"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start = time.time()\n",
    "df_duration_outliers.to_csv(f'./data/{city_name}_duration_outliers-stolen_bikes.csv', index=False)\n",
    "end = time.time()\n",
    "end - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faee4583",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
